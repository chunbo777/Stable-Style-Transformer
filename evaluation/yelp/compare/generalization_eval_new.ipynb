{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "output_path = '/DATA/joosung/controllable_english/evaluation/yelp/compare/yelp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  B_GST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 43.445969010960475\n",
      "model:  CrossAligned\n",
      "BLEU score: 17.015450645847654\n",
      "model:  DeleteAndRetrieve\n",
      "BLEU score: 34.47547504586853\n",
      "model:  DeleteOnly\n",
      "BLEU score: 33.93628403240791\n",
      "model:  G_GST\n",
      "BLEU score: 43.94119083533587\n",
      "model:  humanDRG\n",
      "BLEU score: 26.9693395196322\n",
      "model:  humanDUAL\n",
      "BLEU score: 36.79476631343228\n",
      "model:  input_copy\n",
      "BLEU score: 100.0\n",
      "model:  multi_decoder\n",
      "BLEU score: 40.80852135369808\n",
      "model:  RetrieveOnly\n",
      "BLEU score: 0.880880862993207\n",
      "model:  StyleEmbedding\n",
      "BLEU score: 71.80395314507336\n",
      "model:  TemplateBased\n",
      "BLEU score: 48.674772350951216\n",
      "model:  BackTranslation\n",
      "BLEU score: 0.6682748635680508\n",
      "model:  DualRL\n",
      "BLEU score: 58.72439096444732\n",
      "model:  UnpairedRL\n",
      "BLEU score: 42.28547851663075\n"
     ]
    }
   ],
   "source": [
    "### self-BLEU\n",
    "import glob\n",
    "neg_out_files = glob.glob(output_path + '*test.0*')\n",
    "pos_out_files = glob.glob(output_path + '*test.1*')\n",
    "\n",
    "for i in range(len(neg_out_files)):\n",
    "    print(\"model: \", neg_out_files[i].split('.')[-1])\n",
    "    \n",
    "    neg_data_open = open(neg_out_files[i], \"r\")\n",
    "    neg_data_dataset = neg_data_open.readlines()\n",
    "    neg_len = len(neg_data_dataset)\n",
    "    neg_data_open.close()\n",
    "    \n",
    "    neg_bleu_1 = 0\n",
    "    neg_bleu_2 = 0\n",
    "    neg_bleu_3 = 0\n",
    "    neg_bleu_4 = 0\n",
    "    neg_bleu_score = 0\n",
    "    for k in range(neg_len):\n",
    "        ori_sen = neg_data_dataset[k].split('\\t')[0]\n",
    "        out_sen = neg_data_dataset[k].split('\\t')[1]\n",
    "        \n",
    "        ori_tokens=word_tokenize(ori_sen)\n",
    "        out_tokens=word_tokenize(out_sen)\n",
    "        ori_tokens = [ori_tokens]\n",
    "        \n",
    "        bleu_1_score = sentence_bleu(ori_tokens, out_tokens, weights=(1, 0, 0, 0))\n",
    "        bleu_2_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.5, 0.5, 0, 0))\n",
    "        bleu_3_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.33, 0.33, 0.33, 0))\n",
    "        bleu_4_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "        \n",
    "        neg_bleu_1 += bleu_1_score\n",
    "        neg_bleu_2 += bleu_2_score\n",
    "        neg_bleu_3 += bleu_3_score\n",
    "        neg_bleu_4 += bleu_4_score\n",
    "        neg_bleu_score += min(1, len(out_tokens)/len(ori_tokens))*((bleu_1_score*bleu_2_score*bleu_3_score*bleu_4_score)**(0.25))\n",
    "    \n",
    "    pos_out_name = neg_out_files[i].split('.0.')[0]+'.1.'+neg_out_files[i].split('.0.')[-1]\n",
    "    pos_data_open = open(pos_out_name, \"r\")\n",
    "    pos_data_dataset = pos_data_open.readlines()\n",
    "    pos_len = len(neg_data_dataset)\n",
    "    pos_data_open.close()\n",
    "    \n",
    "    pos_bleu_1 = 0\n",
    "    pos_bleu_2 = 0\n",
    "    pos_bleu_3 = 0\n",
    "    pos_bleu_4 = 0\n",
    "    pos_bleu_score = 0\n",
    "    for k in range(pos_len):\n",
    "        ori_sen = pos_data_dataset[k].split('\\t')[0]\n",
    "        out_sen = pos_data_dataset[k].split('\\t')[1]\n",
    "        \n",
    "        ori_tokens=word_tokenize(ori_sen)\n",
    "        out_tokens=word_tokenize(out_sen)\n",
    "        ori_tokens = [ori_tokens]\n",
    "        \n",
    "        bleu_1_score = sentence_bleu(ori_tokens, out_tokens, weights=(1, 0, 0, 0))\n",
    "        bleu_2_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.5, 0.5, 0, 0))\n",
    "        bleu_3_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.33, 0.33, 0.33, 0))\n",
    "        bleu_4_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "        \n",
    "        pos_bleu_1 += bleu_1_score\n",
    "        pos_bleu_2 += bleu_2_score\n",
    "        pos_bleu_3 += bleu_3_score\n",
    "        pos_bleu_4 += bleu_4_score\n",
    "        pos_bleu_score += min(1, len(out_tokens)/len(ori_tokens))*((bleu_1_score*bleu_2_score*bleu_3_score*bleu_4_score)**(0.25))\n",
    "    \n",
    "    bleu_1 = (neg_bleu_1+pos_bleu_1)/(neg_len+pos_len)\n",
    "    bleu_2 = (neg_bleu_2+pos_bleu_2)/(neg_len+pos_len)\n",
    "    bleu_3 = (neg_bleu_3+pos_bleu_3)/(neg_len+pos_len)\n",
    "    bleu_4 = (neg_bleu_4+pos_bleu_4)/(neg_len+pos_len)\n",
    "    blue_score = (neg_bleu_score+pos_bleu_score)/(neg_len+pos_len)\n",
    "#     print('BLEU_1 score: {}'.format(bleu_1))\n",
    "#     print('BLEU_2 score: {}'.format(bleu_2))\n",
    "#     print('BLEU_3 score: {}'.format(bleu_3))\n",
    "#     print('BLEU_4 score: {}'.format(bleu_4))\n",
    "#     print('Average: ', (bleu_1+bleu_2+bleu_3+bleu_4)/4*100)\n",
    "    print('BLEU score: {}'.format(blue_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  B_GST\n",
      "BLEU score: 13.492065562759128\n",
      "model:  CrossAligned\n",
      "BLEU score: 4.336741798013845\n",
      "model:  DeleteAndRetrieve\n",
      "BLEU score: 9.823532194540812\n",
      "model:  DeleteOnly\n",
      "BLEU score: 9.28509410000901\n",
      "model:  G_GST\n",
      "BLEU score: 13.277896101990041\n",
      "model:  humanDRG\n",
      "BLEU score: 53.3542075695261\n",
      "model:  humanDUAL\n",
      "BLEU score: 33.01971646649611\n",
      "model:  input_copy\n",
      "BLEU score: 21.014577208796236\n",
      "model:  multi_decoder\n",
      "BLEU score: 8.237610334097875\n",
      "model:  RetrieveOnly\n",
      "BLEU score: 0.42682838584074756\n",
      "model:  StyleEmbedding\n",
      "BLEU score: 13.647917881993484\n",
      "model:  TemplateBased\n",
      "BLEU score: 12.859593684528473\n",
      "model:  BackTranslation\n",
      "BLEU score: 0.5202224657007146\n",
      "model:  DualRL\n",
      "BLEU score: 17.709507727994133\n",
      "model:  UnpairedRL\n",
      "BLEU score: 10.601903591684167\n"
     ]
    }
   ],
   "source": [
    "### human-BLEU\n",
    "import glob\n",
    "human_path = '/DATA/joosung/controllable_english/evaluation/yelp/human/'\n",
    "neg_human_DRG = human_path + 'sentiment.test.0.humanDRG'\n",
    "neg_human_DRG_open = open(neg_human_DRG, \"r\")\n",
    "neg_human_DRG_dataset = neg_human_DRG_open.readlines()\n",
    "neg_human_DRG_open.close()\n",
    "\n",
    "pos_human_DRG = human_path + 'sentiment.test.1.humanDRG'\n",
    "pos_human_DRG_open = open(pos_human_DRG, \"r\")\n",
    "pos_human_DRG_dataset = pos_human_DRG_open.readlines()\n",
    "pos_human_DRG_open.close()\n",
    "\n",
    "neg_human_DUAL = human_path + 'sentiment.test.0.humanDUAL'\n",
    "neg_human_DUAL_open = open(neg_human_DUAL, \"r\")\n",
    "neg_human_DUAL_dataset = neg_human_DUAL_open.readlines()\n",
    "neg_human_DUAL_open.close()\n",
    "\n",
    "pos_human_DUAL = human_path + 'sentiment.test.0.humanDUAL'\n",
    "pos_human_DUAL_open = open(pos_human_DUAL, \"r\")\n",
    "pos_human_DUAL_dataset = pos_human_DUAL_open.readlines()\n",
    "pos_human_DUAL_open.close()\n",
    "\n",
    "neg_out_files = glob.glob(output_path + '*test.0*')\n",
    "pos_out_files = glob.glob(output_path + '*test.1*')\n",
    "for i in range(len(neg_out_files)):\n",
    "    print(\"model: \", neg_out_files[i].split('.')[-1])\n",
    "    \n",
    "    neg_data_open = open(neg_out_files[i], \"r\")\n",
    "    neg_data_dataset = neg_data_open.readlines()\n",
    "    neg_len = len(neg_data_dataset)\n",
    "    neg_data_open.close()\n",
    "    \n",
    "    neg_bleu_score = 0\n",
    "    for k in range(neg_len):\n",
    "        out_sen = neg_data_dataset[k].split('\\t')[1]\n",
    "        out_tokens=word_tokenize(out_sen)\n",
    "        \n",
    "        ### human DRG \n",
    "        ori_sen = neg_human_DRG_dataset[k].split('\\t')[1]        \n",
    "        ori_tokens=word_tokenize(ori_sen)        \n",
    "        ori_tokens = [ori_tokens]\n",
    "        \n",
    "        bleu_1_score = sentence_bleu(ori_tokens, out_tokens, weights=(1, 0, 0, 0))\n",
    "        bleu_2_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.5, 0.5, 0, 0))\n",
    "        bleu_3_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.33, 0.33, 0.33, 0))\n",
    "        bleu_4_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "        \n",
    "        neg_bleu_score += min(1, len(out_tokens)/len(ori_tokens))*((bleu_1_score*bleu_2_score*bleu_3_score*bleu_4_score)**(0.25))\n",
    "        \n",
    "        ### human DUAL\n",
    "        ori_sen = neg_human_DUAL_dataset[k].split('\\t')[1]        \n",
    "        ori_tokens=word_tokenize(ori_sen)\n",
    "        ori_tokens = [ori_tokens]\n",
    "        \n",
    "        bleu_1_score = sentence_bleu(ori_tokens, out_tokens, weights=(1, 0, 0, 0))\n",
    "        bleu_2_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.5, 0.5, 0, 0))\n",
    "        bleu_3_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.33, 0.33, 0.33, 0))\n",
    "        bleu_4_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "        \n",
    "        neg_bleu_score += min(1, len(out_tokens)/len(ori_tokens))*((bleu_1_score*bleu_2_score*bleu_3_score*bleu_4_score)**(0.25))\n",
    "    \n",
    "    pos_out_name = neg_out_files[i].split('.0.')[0]+'.1.'+neg_out_files[i].split('.0.')[-1]\n",
    "    pos_data_open = open(pos_out_name, \"r\")\n",
    "    pos_data_dataset = pos_data_open.readlines()\n",
    "    pos_len = len(neg_data_dataset)\n",
    "    pos_data_open.close()\n",
    "    \n",
    "    pos_bleu_score = 0\n",
    "    for k in range(pos_len):\n",
    "        out_sen = pos_data_dataset[k].split('\\t')[1]\n",
    "        out_tokens=word_tokenize(out_sen)\n",
    "        \n",
    "        ### human DRG \n",
    "        ori_sen = pos_human_DRG_dataset[k].split('\\t')[1]        \n",
    "        ori_tokens=word_tokenize(ori_sen)        \n",
    "        ori_tokens = [ori_tokens]\n",
    "        \n",
    "        bleu_1_score = sentence_bleu(ori_tokens, out_tokens, weights=(1, 0, 0, 0))\n",
    "        bleu_2_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.5, 0.5, 0, 0))\n",
    "        bleu_3_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.33, 0.33, 0.33, 0))\n",
    "        bleu_4_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "        \n",
    "        pos_bleu_score += min(1, len(out_tokens)/len(ori_tokens))*((bleu_1_score*bleu_2_score*bleu_3_score*bleu_4_score)**(0.25))\n",
    "        \n",
    "        ### human DUAL\n",
    "        ori_sen = pos_human_DUAL_dataset[k].split('\\t')[1]        \n",
    "        ori_tokens=word_tokenize(ori_sen)\n",
    "        ori_tokens = [ori_tokens]\n",
    "        \n",
    "        bleu_1_score = sentence_bleu(ori_tokens, out_tokens, weights=(1, 0, 0, 0))\n",
    "        bleu_2_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.5, 0.5, 0, 0))\n",
    "        bleu_3_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.33, 0.33, 0.33, 0))\n",
    "        bleu_4_score = sentence_bleu(ori_tokens, out_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "        \n",
    "        pos_bleu_score += min(1, len(out_tokens)/len(ori_tokens))*((bleu_1_score*bleu_2_score*bleu_3_score*bleu_4_score)**(0.25))\n",
    "    \n",
    "    blue_score = (neg_bleu_score+pos_bleu_score)/((neg_len+pos_len)*2)\n",
    "    print('BLEU score: {}'.format(blue_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from transformers import *\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "import json\n",
    "f = open('../gpt_yelp_vocab.json')\n",
    "token2num = json.load(f)\n",
    "\n",
    "num2token = {}\n",
    "for key, value in token2num.items():\n",
    "    num2token[value] = key\n",
    "import sys    \n",
    "sys.path.insert(0, \"/DATA/joosung/controllable_english/yelp/visual_v3_1\")\n",
    "from dis_model import *\n",
    "dismodel = findattribute().cuda()\n",
    "\n",
    "i='final'\n",
    "dismodel_name='cls_model_' + str(i)\n",
    "dismodel.load_state_dict(torch.load('/DATA/joosung/controllable_english/yelp/visual_v3_1/models/{}'.format(dismodel_name)))\n",
    "dismodel.eval()\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  B_GST\n",
      "Accuracy: 86.1%\n",
      "model:  CrossAligned\n",
      "Accuracy: 74.8%\n",
      "model:  DeleteAndRetrieve\n",
      "Accuracy: 87.7%\n",
      "model:  DeleteOnly\n",
      "Accuracy: 84.8%\n",
      "model:  G_GST\n",
      "Accuracy: 77.2%\n",
      "model:  humanDRG\n",
      "Accuracy: 72.8%\n",
      "model:  humanDUAL\n",
      "Accuracy: 77.0%\n",
      "model:  input_copy\n",
      "Accuracy: 3.5000000000000004%\n",
      "model:  multi_decoder\n",
      "Accuracy: 46.400000000000006%\n",
      "model:  RetrieveOnly\n",
      "Accuracy: 98.4%\n",
      "model:  StyleEmbedding\n",
      "Accuracy: 8.9%\n",
      "model:  TemplateBased\n",
      "Accuracy: 79.7%\n",
      "model:  BackTranslation\n",
      "Accuracy: 96.2%\n",
      "model:  DualRL\n",
      "Accuracy: 86.8%\n",
      "model:  UnpairedRL\n",
      "Accuracy: 47.699999999999996%\n"
     ]
    }
   ],
   "source": [
    "### classifier accuracy\n",
    "import glob\n",
    "neg_out_files = glob.glob(output_path + '*test.0*')\n",
    "pos_out_files = glob.glob(output_path + '*test.1*')\n",
    "\n",
    "for i in range(len(neg_out_files)):\n",
    "    print(\"model: \", neg_out_files[i].split('.')[-1])\n",
    "    \n",
    "    neg_data_open = open(neg_out_files[i], \"r\")\n",
    "    neg_data_dataset = neg_data_open.readlines()\n",
    "    neg_len = len(neg_data_dataset)\n",
    "    neg_data_open.close()\n",
    "    \n",
    "    neg_correct = 0\n",
    "    for k in range(neg_len):\n",
    "        out_sen = neg_data_dataset[k].split('\\t')[1].strip()\n",
    "        \n",
    "        token_idx = torch.tensor(gpt_tokenizer.encode(out_sen)).unsqueeze(0).cuda()\n",
    "\n",
    "        \"\"\"discriminator\"\"\"\n",
    "        if token_idx.shape[1] != 0:\n",
    "            result = dismodel.discriminator(token_idx=token_idx).argmax(1).cpu().numpy()[0]    \n",
    "            if result == 1: ## style transfer so result must be 1(positive)\n",
    "                neg_correct += 1\n",
    "            \n",
    "    pos_out_name = neg_out_files[i].split('.0.')[0]+'.1.'+neg_out_files[i].split('.0.')[-1]\n",
    "    pos_data_open = open(pos_out_name, \"r\")\n",
    "    pos_data_dataset = pos_data_open.readlines()\n",
    "    pos_len = len(neg_data_dataset)\n",
    "    pos_data_open.close()\n",
    "    \n",
    "    pos_correct = 0\n",
    "    for k in range(pos_len):\n",
    "        out_sen = pos_data_dataset[k].split('\\t')[1].strip()\n",
    "        \n",
    "        token_idx = torch.tensor(gpt_tokenizer.encode(out_sen)).unsqueeze(0).cuda()\n",
    "\n",
    "        \"\"\"discriminator\"\"\"\n",
    "        if token_idx.shape[1] != 0:\n",
    "            result = dismodel.discriminator(token_idx=token_idx).argmax(1).cpu().numpy()[0]    \n",
    "            if result == 0: ## style transfer so result must be 0(negative)\n",
    "                pos_correct += 1\n",
    "    \n",
    "    Acc = (neg_correct+pos_correct)/(neg_len+pos_len)*100\n",
    "    print(\"Accuracy: {}%\".format(Acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62228d40d1a74b5e84a155a25cae4406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7debfcf4b1e439da4c85c668775a99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.76 seconds, 362.78 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acd1d7713a94b1cb2b5bb85e7582eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1244eee0ebe445ce9cc6c2a72f686e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.71 seconds, 369.57 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ae92940e2140869baf721735ed6177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6ece01d0a04bff94f81484be280c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.85 seconds, 350.91 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b698c4cf794ead9300f50c9a273a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e153345101664b70b1595a4d906f9ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.69 seconds, 371.20 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e52a37f92e49c08625922bd3d612ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6e1b7cfda541a9b7f27e7812959033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.83 seconds, 353.91 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53bbbe4c6d14cbb9808a935eeacadd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bd181d560e49289235dc00d5482394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.78 seconds, 359.08 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa09b5689f64cbaa1ff20f1228c46e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d1652dfcae4ab9a51d63da90c01e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.78 seconds, 359.60 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174d7d4416f8473097442f2b094b90b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2ea047776848f59fea80871ff70f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.81 seconds, 355.40 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb08c9d8d9fd4ffaaf696de00a5d100c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9be14958a14593969a4509c79b4ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.75 seconds, 363.12 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58244d93041a4e67be857108b37db92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f5c352bcdc48bf93c239c6e0ea2f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.75 seconds, 363.72 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2d1c4725f845138f888bf8164d58d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1968a54c5849d6b2fd4aac1c271ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 1.45 seconds, 689.43 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99f159fb9514137be1dca5fb58d9c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eaaa3fad3a3455e9bb0bbc7f3bfc777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.69 seconds, 372.32 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00aa159b195945198f9d84045b4287f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb62d9345cee433c9715008aa962f21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.69 seconds, 371.88 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41921a089e34b95a274118804c8c664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27bd8d1c8c74ffdb6a9e68c88efd82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 1.46 seconds, 685.66 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0865f26de94134adc21a226f231305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cef052c9c2a450b82d3eab16a59447f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.73 seconds, 365.94 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20bc78aab506451a974641362140f86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7422dc5896d34dde8aa4e29be01b6833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.74 seconds, 364.45 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba8481cedb0419e8c8216f34577661c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58449365afce476481d45d4a6f1ba036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.68 seconds, 373.43 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077b0316a33d4683b2621353a342cef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62037f9727ab4b828f288b3b60707f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.71 seconds, 368.73 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff692464aca24f0aa0e42166df45db8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=28), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0722e27b766f47429f594710dd0c3a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.55 seconds, 392.33 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8508bb14f6dd48f5a1b23b1162efefb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=28), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c04bc8fdc5b4cadb86ca4261b0ecb91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.56 seconds, 391.11 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679dd359d4de4128855fb232b8e10f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823542baddf540cb948dcbc238042d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.78 seconds, 360.23 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3727feb9fbb4264bb1a4b6043dad078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb21af725d534f0886239c5e149921ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.73 seconds, 365.93 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde2ee21237a4d7da866e415352bfa89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f5ea65de47428aba012b56084e5ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.71 seconds, 369.52 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e4f4563a5741a5a717ef1ee96d767a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2b0a7e25f44037a69654f99a169458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.73 seconds, 366.91 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cca8884b57f47b589ffe7b60f80db0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d899523c5b84827bf51ec2884432080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.71 seconds, 368.44 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e874e945cd42bd97beef48afd0b7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b556ad66f1842c394cf2b714a8a795a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.68 seconds, 372.49 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd22d25e609a400299e45cee25b59c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718cabb4be55404380bf62967b93d0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.74 seconds, 365.05 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbd5441464a4c19a8bb82cf9da916f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb512b384bc4f75aeedee7d827826a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.75 seconds, 364.15 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ecbfa362794849a6665b40b0521c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d362cae3e53a482aad7e746bcf29c176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.65 seconds, 377.81 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b71c03a4d3407e8d3fd87ab6105d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88a498cfa4c468d80f06f7f893907be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.64 seconds, 378.69 sentences/sec\n",
      "model:  B_GST\n",
      "BERT score(F1): 91.77927347421647\n",
      "\n",
      "model:  CrossAligned\n",
      "BERT score(F1): 88.11618057489396\n",
      "\n",
      "model:  DeleteAndRetrieve\n",
      "BERT score(F1): 89.3871376991272\n",
      "\n",
      "model:  DeleteOnly\n",
      "BERT score(F1): 89.2835805118084\n",
      "\n",
      "model:  G_GST\n",
      "BERT score(F1): 91.14643557667732\n",
      "\n",
      "model:  humanDRG\n",
      "BERT score(F1): 95.82975050508976\n",
      "\n",
      "model:  humanDUAL\n",
      "BERT score(F1): 95.82975061833858\n",
      "\n",
      "model:  input_copy\n",
      "BERT score(F1): 93.18091272413731\n",
      "\n",
      "model:  multi_decoder\n",
      "BERT score(F1): 88.35219190120696\n",
      "\n",
      "model:  RetrieveOnly\n",
      "BERT score(F1): 86.32608650922775\n",
      "\n",
      "model:  StyleEmbedding\n",
      "BERT score(F1): 90.5580698609352\n",
      "\n",
      "model:  TemplateBased\n",
      "BERT score(F1): 89.70653468668462\n",
      "\n",
      "model:  BackTranslation\n",
      "BERT score(F1): 87.35862209498882\n",
      "\n",
      "model:  DualRL\n",
      "BERT score(F1): 92.1440402507782\n",
      "\n",
      "model:  UnpairedRL\n",
      "BERT score(F1): 88.51446964144706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### BERT score with human reference\n",
    "from bert_score import score\n",
    "import glob\n",
    "human_path = '/DATA/joosung/controllable_english/evaluation/yelp/compare1/yelp/'\n",
    "neg_human_DRG = human_path + 'sentiment.test.0.humanDRG'\n",
    "neg_human_DRG_open = open(neg_human_DRG, \"r\")\n",
    "neg_human_DRG_dataset = neg_human_DRG_open.readlines()\n",
    "neg_human_DRG_open.close()\n",
    "\n",
    "pos_human_DRG = human_path + 'sentiment.test.1.humanDRG'\n",
    "pos_human_DRG_open = open(pos_human_DRG, \"r\")\n",
    "pos_human_DRG_dataset = pos_human_DRG_open.readlines()\n",
    "pos_human_DRG_open.close()\n",
    "\n",
    "neg_human_DUAL = human_path + 'sentiment.test.0.humanDUAL'\n",
    "neg_human_DUAL_open = open(neg_human_DUAL, \"r\")\n",
    "neg_human_DUAL_dataset = neg_human_DUAL_open.readlines()\n",
    "neg_human_DUAL_open.close()\n",
    "\n",
    "pos_human_DUAL = human_path + 'sentiment.test.1.humanDUAL'\n",
    "pos_human_DUAL_open = open(pos_human_DUAL, \"r\")\n",
    "pos_human_DUAL_dataset = pos_human_DUAL_open.readlines()\n",
    "pos_human_DUAL_open.close()\n",
    "\n",
    "DRG_refs = []\n",
    "neg_len = len(neg_human_DRG_dataset)\n",
    "pos_len = len(pos_human_DRG_dataset)\n",
    "for k in range(neg_len):\n",
    "    ref_sen = neg_human_DRG_dataset[k].split('\\t')[1]\n",
    "    DRG_refs.append(ref_sen)\n",
    "for k in range(pos_len):\n",
    "    ref_sen = pos_human_DRG_dataset[k].split('\\t')[1]\n",
    "    DRG_refs.append(ref_sen)\n",
    "\n",
    "DUAL_refs = []\n",
    "neg_len = len(neg_human_DUAL_dataset)\n",
    "pos_len = len(pos_human_DUAL_dataset)\n",
    "for k in range(neg_len):\n",
    "    ref_sen = neg_human_DUAL_dataset[k].split('\\t')[1]\n",
    "    DUAL_refs.append(ref_sen)\n",
    "for k in range(pos_len):\n",
    "    ref_sen = pos_human_DUAL_dataset[k].split('\\t')[1]\n",
    "    DUAL_refs.append(ref_sen)\n",
    "    \n",
    "neg_out_files = glob.glob(output_path + '*test.0*')\n",
    "pos_out_files = glob.glob(output_path + '*test.1*')\n",
    "model_name=[]\n",
    "score_list=[]\n",
    "for i in range(len(neg_out_files)):    \n",
    "    cands = []\n",
    "    neg_data_open = open(neg_out_files[i], \"r\")\n",
    "    neg_data_dataset = neg_data_open.readlines()\n",
    "    neg_len = len(neg_data_dataset)\n",
    "    neg_data_open.close()\n",
    "    \n",
    "    for k in range(neg_len):\n",
    "        out_sen = neg_data_dataset[k].split('\\t')[1]\n",
    "        cands.append(out_sen)\n",
    "    \n",
    "    pos_out_name = neg_out_files[i].split('.0.')[0]+'.1.'+neg_out_files[i].split('.0.')[-1]\n",
    "    pos_data_open = open(pos_out_name, \"r\")\n",
    "    pos_data_dataset = pos_data_open.readlines()\n",
    "    pos_len = len(neg_data_dataset)\n",
    "    pos_data_open.close()\n",
    "    \n",
    "    for k in range(pos_len):\n",
    "        out_sen = pos_data_dataset[k].split('\\t')[1]\n",
    "        cands.append(out_sen)\n",
    "\n",
    "    P, R, DRG_F1 = score(cands, DRG_refs, lang='en', verbose=True)\n",
    "    DRG_F1_list=list(DRG_F1.numpy())\n",
    "    DRG_BERT_scroe = sum(DRG_F1_list)/len(DRG_F1_list)\n",
    "    \n",
    "    P, R, DUAL_F1 = score(cands, DUAL_refs, lang='en', verbose=True)\n",
    "    DUAL_F1_list=list(DUAL_F1.numpy())\n",
    "    DUAL_BERT_scroe = sum(DUAL_F1_list)/len(DUAL_F1_list)\n",
    "    \n",
    "    BERT_score = (DRG_BERT_scroe+DUAL_BERT_scroe)/2    \n",
    "    \n",
    "    model_name.append(neg_out_files[i].split('.')[-1])\n",
    "    score_list.append(BERT_score)\n",
    "for i in range(len(model_name)):\n",
    "    print(\"model: \", model_name[i])\n",
    "    print('BERT score(F1): {}'.format(score_list[i]*100))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1611bcafe5734e44baf81e260f6a5a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efca44fae81e4be9a8a2eb7f428c5932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.71 seconds, 369.08 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8d26a37bf341a19fa947c10fd7ef80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab10a6fdd704625bb338e9907c270e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.75 seconds, 363.02 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9db916f7484c529da81939e2074d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478dad50ef1746c0aba36f2492b81dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.76 seconds, 362.42 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28af88171e7f4bd68c94778fab90adf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741a80cc555a47a8b2950f64b12a301e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.79 seconds, 358.25 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003db9f0e9ca41d8b8bffdaf88a65eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae59fdc7150443181fbe8a28a3934fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.77 seconds, 360.40 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8dd8745ce9437faedb366437f8a8a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245fdd02ff494beba4f6c45cec47f862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.75 seconds, 363.77 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4edc76093646c2bda047640930245b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8b104f1b79496da5a0aeae9f742319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.78 seconds, 359.57 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4ca72a22cb411b8ad966a428db2388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7b979dd1bc4ee19cdf4c632324791f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 1.48 seconds, 675.38 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc95d28c14d84cce967ef27cfc33116e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=29), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36f5fd42e0d4512b122a7f6c05329c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.50 seconds, 400.39 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64abeb1a665849b28eb4de9fd0e6dce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=28), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58dc0d30064c4793a8c0f35c3c18ed5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.59 seconds, 386.38 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf32ec506e91493497ea53196ebf82a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1f74c946f04113abc6cc23542ce0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.14 seconds, 466.22 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c7cd177f234a4885c94459e946f581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece32a4b9a844234aee7814e30f31f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.70 seconds, 370.03 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff81f1a225134f15b635c188955889b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eadc3d2dbabf49ed9d4b86d46a51eb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.72 seconds, 368.18 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6024ee9750c478d8d821960b421bf6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb12bc9c15b14f92b7f3d34c53871e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.73 seconds, 365.89 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a3bc6921ff4f49b6402e1bcbd0f9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ebb134c6d6479490bc141cedc06f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2.64 seconds, 379.06 sentences/sec\n",
      "model:  B_GST\n",
      "BERT score(F1): 94.15053763985634\n",
      "\n",
      "model:  CrossAligned\n",
      "BERT score(F1): 89.72920480370522\n",
      "\n",
      "model:  DeleteAndRetrieve\n",
      "BERT score(F1): 91.31102452278137\n",
      "\n",
      "model:  DeleteOnly\n",
      "BERT score(F1): 91.22268363833427\n",
      "\n",
      "model:  G_GST\n",
      "BERT score(F1): 93.56900192499161\n",
      "\n",
      "model:  humanDRG\n",
      "BERT score(F1): 92.73307495117187\n",
      "\n",
      "model:  humanDUAL\n",
      "BERT score(F1): 93.62875049710274\n",
      "\n",
      "model:  input_copy\n",
      "BERT score(F1): 100.00000440478325\n",
      "\n",
      "model:  multi_decoder\n",
      "BERT score(F1): 91.08903203606606\n",
      "\n",
      "model:  RetrieveOnly\n",
      "BERT score(F1): 86.76496728658675\n",
      "\n",
      "model:  StyleEmbedding\n",
      "BERT score(F1): 95.46446869373322\n",
      "\n",
      "model:  TemplateBased\n",
      "BERT score(F1): 92.27526341676712\n",
      "\n",
      "model:  BackTranslation\n",
      "BERT score(F1): 87.76175565719605\n",
      "\n",
      "model:  DualRL\n",
      "BERT score(F1): 95.11633821725846\n",
      "\n",
      "model:  UnpairedRL\n",
      "BERT score(F1): 91.09422641396523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### BERT score with self-reference\n",
    "from bert_score import score\n",
    "import glob\n",
    "\n",
    "neg_out_files = glob.glob(output_path + '*test.0*')\n",
    "pos_out_files = glob.glob(output_path + '*test.1*')\n",
    "\n",
    "neg_human = neg_out_files[0]\n",
    "neg_human_open = open(neg_human, \"r\")\n",
    "neg_human_dataset = neg_human_open.readlines()\n",
    "neg_human_open.close()\n",
    "\n",
    "pos_human = pos_out_files[0]\n",
    "pos_human_open = open(pos_human, \"r\")\n",
    "pos_human_dataset = pos_human_open.readlines()\n",
    "pos_human_open.close()\n",
    "\n",
    "refs = []\n",
    "neg_len = len(neg_human_dataset)\n",
    "pos_len = len(pos_human_dataset)\n",
    "for k in range(neg_len):\n",
    "    ref_sen = neg_human_dataset[k].split('\\t')[0]\n",
    "    refs.append(ref_sen)\n",
    "for k in range(pos_len):\n",
    "    ref_sen = pos_human_dataset[k].split('\\t')[0]\n",
    "    refs.append(ref_sen)\n",
    "        \n",
    "model_name=[]\n",
    "score_list=[]    \n",
    "for i in range(len(neg_out_files)):\n",
    "    cands = []\n",
    "    neg_data_open = open(neg_out_files[i], \"r\")\n",
    "    neg_data_dataset = neg_data_open.readlines()\n",
    "    neg_len = len(neg_data_dataset)\n",
    "    neg_data_open.close()\n",
    "    \n",
    "    for k in range(neg_len):\n",
    "        out_sen = neg_data_dataset[k].split('\\t')[1]\n",
    "        cands.append(out_sen)\n",
    "    \n",
    "    pos_out_name = neg_out_files[i].split('.0.')[0]+'.1.'+neg_out_files[i].split('.0.')[-1]\n",
    "    pos_data_open = open(pos_out_name, \"r\")\n",
    "    pos_data_dataset = pos_data_open.readlines()\n",
    "    pos_len = len(neg_data_dataset)\n",
    "    pos_data_open.close()\n",
    "    \n",
    "    for k in range(pos_len):\n",
    "        out_sen = pos_data_dataset[k].split('\\t')[1]\n",
    "        cands.append(out_sen)\n",
    "\n",
    "    P, R, F1 = score(cands, refs, lang='en', verbose=True)\n",
    "    F1_list=list(F1.numpy())\n",
    "    BERT_score = sum(F1_list)/len(F1_list)\n",
    "    model_name.append(neg_out_files[i].split('.')[-1])\n",
    "    score_list.append(BERT_score)\n",
    "for i in range(len(model_name)):\n",
    "    print(\"model: \", model_name[i])\n",
    "    print('BERT score(F1): {}'.format(score_list[i]*100))\n",
    "    print('')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PPL\n",
    "import torch, os\n",
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device='cpu'\n",
    "model_class, tokenizer_class = (GPT2LMHeadModel, GPT2Tokenizer)\n",
    "gpt2_lm_tokenizer = tokenizer_class.from_pretrained('gpt2-large')\n",
    "gpt2_lm_model = model_class.from_pretrained('gpt2-large')\n",
    "gpt2_lm_model.to(device)\n",
    "gpt2_lm_model.eval()\n",
    "\n",
    "lm_loss = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='none')\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def calculate_ppl_gpt(sentence_batch):\n",
    "    # tokenize the sentences\n",
    "    tokenized_ids = [None for i in range(len(sentence_batch))]\n",
    "    \n",
    "    for i in range(len(sentence_batch)):\n",
    "        tokenized_ids[i] = gpt2_lm_tokenizer.encode(sentence_batch[i])\n",
    "        \n",
    "    sen_lengths = [len(x) for x in tokenized_ids]\n",
    "    max_sen_lenght = max(sen_lengths)\n",
    "    \n",
    "    n_batch = len(sentence_batch)\n",
    "    input_ids = np.zeros( shape=(n_batch, max_sen_lenght), dtype=np.int64)\n",
    "    lm_labels = np.full(shape=(n_batch, max_sen_lenght), fill_value=-1)\n",
    "    \n",
    "    for i, tokens in enumerate(tokenized_ids):\n",
    "        input_ids[i, :len(tokens)] = tokens\n",
    "        lm_labels[i, :len(tokens)-1] = tokens[1:] \n",
    "    \n",
    "    input_ids = torch.tensor(input_ids).to(device)\n",
    "    lm_labels = torch.tensor(lm_labels).to(device)\n",
    "    with torch.no_grad():\n",
    "        lm_pred = gpt2_lm_model(input_ids)\n",
    "    loss_val = lm_loss(lm_pred[0].view(-1, lm_pred[0].size(-1)), lm_labels.view(-1))\n",
    "    normalized_loss = loss_val.view(n_batch,-1).sum(dim= -1) / torch.tensor(sen_lengths, dtype=torch.float32).to(device)\n",
    "    #normalized_loss = loss_val.view(n_batch,-1).sum(dim= -1)\n",
    "    ppl = torch.exp(normalized_loss)\n",
    "    return  ppl.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  B_GST\n",
      "PPL: 184.02350085639952\n",
      "model:  CrossAligned\n",
      "PPL: 319.09726698684693\n",
      "model:  DeleteAndRetrieve\n",
      "PPL: 343.75168181705476\n",
      "model:  DeleteOnly\n",
      "PPL: 279.5456501865387\n",
      "model:  G_GST\n",
      "PPL: 274.24824584198\n",
      "model:  humanDRG\n",
      "PPL: 153.448028380394\n",
      "model:  humanDUAL\n",
      "PPL: 196.15160024261473\n",
      "model:  input_copy\n",
      "PPL: 131.91174020195007\n",
      "model:  multi_decoder\n",
      "PPL: 642.1336257858277\n",
      "model:  RetrieveOnly\n",
      "PPL: 150.6160513896942\n",
      "model:  StyleEmbedding\n",
      "PPL: 379.80506280994416\n",
      "model:  TemplateBased\n",
      "PPL: 375.6218895072937\n",
      "model:  BackTranslation\n",
      "PPL: 148.76635962867738\n",
      "model:  DualRL\n",
      "PPL: 273.72965145874025\n",
      "model:  UnpairedRL\n",
      "PPL: 735.0950142564774\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "neg_out_files = glob.glob(output_path + '*test.0*')\n",
    "pos_out_files = glob.glob(output_path + '*test.1*')\n",
    "for i in range(len(neg_out_files)):\n",
    "    print(\"model: \", neg_out_files[i].split('.')[-1])\n",
    "    \n",
    "    neg_data_open = open(neg_out_files[i], \"r\")\n",
    "    neg_data_dataset = neg_data_open.readlines()\n",
    "    neg_len = len(neg_data_dataset)\n",
    "    neg_data_open.close()\n",
    "    \n",
    "    neg_PPL = 0\n",
    "    for k in range(neg_len):\n",
    "        out_sen = neg_data_dataset[k].split('\\t')[1].strip()\n",
    "        if len(out_sen) != 0:\n",
    "            sample_PPL = calculate_ppl_gpt([out_sen])[0]\n",
    "            neg_PPL += sample_PPL\n",
    "    \n",
    "    pos_out_name = neg_out_files[i].split('.0.')[0]+'.1.'+neg_out_files[i].split('.0.')[-1]\n",
    "    pos_data_open = open(pos_out_name, \"r\")\n",
    "    pos_data_dataset = pos_data_open.readlines()\n",
    "    pos_len = len(neg_data_dataset)\n",
    "    pos_data_open.close()\n",
    "    \n",
    "    pos_PPL = 0\n",
    "    for k in range(pos_len):\n",
    "        out_sen = pos_data_dataset[k].split('\\t')[1].strip()\n",
    "        if len(out_sen) != 0:\n",
    "            sample_PPL = calculate_ppl_gpt([out_sen])[0]\n",
    "            pos_PPL += sample_PPL\n",
    "\n",
    "    total_PPL = (neg_PPL+pos_PPL)/(neg_len+pos_len)\n",
    "    print('PPL: {}'.format(total_PPL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "### PPL\n",
    "import torch, os\n",
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = 'cpu'\n",
    "print(device)\n",
    "\n",
    "lm_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "lm_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "path = '/DATA/joosung/controllable_english/gpt2/finetune_yelp/final/pytorch_model.bin'\n",
    "lm_model_state_dict = torch.load(path)\n",
    "lm_model.load_state_dict(lm_model_state_dict)\n",
    "lm_model.to(device)\n",
    "lm_model.eval()\n",
    "\n",
    "lm_loss = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='none')\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def calculate_ppl_gpt_yelp(sentence_batch):\n",
    "    # tokenize the sentences\n",
    "    tokenized_ids = [None for i in range(len(sentence_batch))]\n",
    "    \n",
    "    for i in range(len(sentence_batch)):\n",
    "        tokenized_ids[i] = lm_tokenizer.encode(sentence_batch[i])\n",
    "        \n",
    "    sen_lengths = [len(x) for x in tokenized_ids]\n",
    "    max_sen_lenght = max(sen_lengths)\n",
    "    \n",
    "    n_batch = len(sentence_batch)\n",
    "    input_ids = np.zeros( shape=(n_batch, max_sen_lenght), dtype=np.int64)\n",
    "    lm_labels = np.full(shape=(n_batch, max_sen_lenght), fill_value=-1)\n",
    "    \n",
    "    for i, tokens in enumerate(tokenized_ids):\n",
    "        input_ids[i, :len(tokens)] = tokens\n",
    "        lm_labels[i, :len(tokens)-1] = tokens[1:] \n",
    "    \n",
    "    input_ids = torch.tensor(input_ids).to(device)\n",
    "    lm_labels = torch.tensor(lm_labels).to(device)\n",
    "    with torch.no_grad():\n",
    "        lm_pred = lm_model(input_ids)\n",
    "    loss_val = lm_loss(lm_pred[0].view(-1, lm_pred[0].size(-1)), lm_labels.view(-1))\n",
    "    normalized_loss = loss_val.view(n_batch,-1).sum(dim= -1) / torch.tensor(sen_lengths, dtype=torch.float32).to(device)\n",
    "    #normalized_loss = loss_val.view(n_batch,-1).sum(dim= -1)\n",
    "    ppl = torch.exp(normalized_loss)\n",
    "    return  ppl.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  B_GST\n",
      "PPL: 165.59385666537284\n",
      "model:  CrossAligned\n",
      "PPL: 69.13188869786262\n",
      "model:  DeleteAndRetrieve\n",
      "PPL: 137.04205481171607\n",
      "model:  DeleteOnly\n",
      "PPL: 171.6625825073719\n",
      "model:  G_GST\n",
      "PPL: 441.3845418429375\n",
      "model:  humanDRG\n",
      "PPL: 121.16750590884685\n",
      "model:  humanDUAL\n",
      "PPL: 178.6316875523329\n",
      "model:  input_copy\n",
      "PPL: 69.71975222992897\n",
      "model:  multi_decoder\n",
      "PPL: 201.5901939446926\n",
      "model:  RetrieveOnly\n",
      "PPL: 150.53571635127068\n",
      "model:  StyleEmbedding\n",
      "PPL: 121.65936390900612\n",
      "model:  TemplateBased\n",
      "PPL: 3258.1898345987797\n",
      "model:  BackTranslation\n",
      "PPL: 30.527025061130523\n",
      "model:  DualRL\n",
      "PPL: 87.7206051094532\n",
      "model:  UnpairedRL\n",
      "PPL: 328.79951017665866\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "neg_out_files = glob.glob(output_path + '*test.0*')\n",
    "pos_out_files = glob.glob(output_path + '*test.1*')\n",
    "for i in range(len(neg_out_files)):\n",
    "    print(\"model: \", neg_out_files[i].split('.')[-1])\n",
    "    \n",
    "    neg_data_open = open(neg_out_files[i], \"r\")\n",
    "    neg_data_dataset = neg_data_open.readlines()\n",
    "    neg_len = len(neg_data_dataset)\n",
    "    neg_data_open.close()\n",
    "    \n",
    "    neg_PPL = 0\n",
    "    for k in range(neg_len):\n",
    "        out_sen = neg_data_dataset[k].split('\\t')[1].strip()\n",
    "        if len(out_sen) != 0:\n",
    "            sample_PPL = calculate_ppl_gpt_yelp([out_sen])[0]\n",
    "            neg_PPL += sample_PPL\n",
    "    \n",
    "    pos_out_name = neg_out_files[i].split('.0.')[0]+'.1.'+neg_out_files[i].split('.0.')[-1]\n",
    "    pos_data_open = open(pos_out_name, \"r\")\n",
    "    pos_data_dataset = pos_data_open.readlines()\n",
    "    pos_len = len(neg_data_dataset)\n",
    "    pos_data_open.close()\n",
    "    \n",
    "    pos_PPL = 0\n",
    "    for k in range(pos_len):\n",
    "        out_sen = pos_data_dataset[k].split('\\t')[1].strip()\n",
    "        if len(out_sen) != 0:\n",
    "            sample_PPL = calculate_ppl_gpt_yelp([out_sen])[0]\n",
    "            pos_PPL += sample_PPL\n",
    "\n",
    "    total_PPL = (neg_PPL+pos_PPL)/(neg_len+pos_len)\n",
    "    print('PPL: {}'.format(total_PPL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
